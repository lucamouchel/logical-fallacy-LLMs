# random seed for batch sampling
seed: 0

# name for this experiment in the local run directory and on wandb
exp_name: evaluate


dpo_ckpt: null

# which dataset(s) to train on; can pass a list like datasets=[hh,shp]
datasets:
- cckg

# wandb configuration
wandb:
  enabled: true
  entity: null
  project: "direct-preference-optimization"

# to create the local run directory and cache models/datasets,
#   we will try each of these directories in order; if none exist,
#   we will create the last one and use it
local_dirs:
  - /scr-ssd
  - /scr
  - .cache

# an OmegaConf resolver that returns the local run directory, calling a function in utils.py
local_run_dir: ${get_local_run_dir:${exp_name},${local_dirs}}

# the learning rate
lr: 5e-7

# number of steps to accumulate over for each batch
#   (e.g. if batch_size=4 and gradient_accumulation_steps=2, then we will
#   accumulate gradients over 2 microbatches of size 2)

# the maximum allowed length for an input (prompt + response)
max_length: 512

# the maximum allowed length for a prompt
max_prompt_length: 256

reference_ckpt: null
# whether or not to use activation/gradient checkpointing
activation_checkpointing: false

# prevent wandb from logging more than once per minimum_log_interval_secs
minimum_log_interval_secs: 1.0

defaults:
- _self_
- model: t5-base # basic model configuration
- loss: sft # which loss function, either sft or dpo (specify loss.beta if using dpo)
