{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  utils, Trainer, TrainingArguments, ElectraTokenizer, ElectraForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "import os\n",
    "from performance import PerformanceSaver\n",
    "from bertviz import model_view\n",
    "utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_SAVED_MODEL = False\n",
    "AUGMENT_WITH_NEUTRAL = True\n",
    "saved_model_path = \"models/binary/electra_classifier\"\n",
    "model_name = \"howey/electra-base-mnli\"\n",
    "data_dir = \"data/argumentation\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train_iam.tsv'), sep='\\t')\n",
    "dev_df = pd.read_csv(os.path.join(data_dir, 'dev_iam.txt'), sep='\\t')\n",
    "test_df = pd.read_csv(os.path.join(data_dir, 'test_iam.txt'), sep='\\t')\n",
    "all_claims = pd.read_csv(os.path.join(data_dir, 'claims.txt'), sep='\\t')\n",
    "np.random.seed(42)\n",
    "\n",
    "if AUGMENT_WITH_NEUTRAL:\n",
    "    neutral_claims = all_claims[all_claims.type=='O'] \n",
    "    lower_bound = 0\n",
    "    \n",
    "    min_train_label = min(train_df['label'].value_counts())\n",
    "    train_sample = neutral_claims.iloc[:min_train_label]\n",
    "    train_df = pd.concat([train_df, train_sample]).sample(frac=1)\n",
    "    lower_bound = min_train_label\n",
    "    \n",
    "    min_dev_label = min(dev_df['label'].value_counts())\n",
    "    dev_sample = neutral_claims.iloc[lower_bound: lower_bound + min_dev_label]    \n",
    "    dev_df = pd.concat([dev_df, dev_sample]).sample(frac=1)\n",
    "    lower_bound = lower_bound + min_dev_label\n",
    "    \n",
    "    min_test_label = min(dev_df['label'].value_counts())\n",
    "    test_sample = neutral_claims.iloc[lower_bound: lower_bound + min_test_label]    \n",
    "    test_df = pd.concat([test_df, test_sample]).sample(frac=1)\n",
    "    \n",
    "    \n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_df['label'])\n",
    "train_df['label'] = label_encoder.transform(train_df['label'])\n",
    "dev_df['label'] = label_encoder.transform(dev_df['label'])\n",
    "test_df['label'] = label_encoder.transform(test_df['label'])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df),\n",
    "    'validation': Dataset.from_pandas(dev_df),\n",
    "    'test': Dataset.from_pandas(test_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=len(label_encoder.classes_)\n",
    "ignore_mismatched_sizes=True\n",
    "classifier_dropout=0.1\n",
    "output_attentions=False\n",
    "\n",
    "if LOAD_SAVED_MODEL:\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(saved_model_path)\n",
    "    model = ElectraForSequenceClassification.from_pretrained(saved_model_path, num_labels=num_labels, ignore_mismatched_sizes=ignore_mismatched_sizes, classifier_dropout=classifier_dropout, output_attentions=output_attentions)\n",
    "else:\n",
    "    tokenizer = ElectraTokenizer.from_pretrained(model_name)\n",
    "    model = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, ignore_mismatched_sizes=ignore_mismatched_sizes, classifier_dropout=classifier_dropout, output_attentions=output_attentions)\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "        model = model.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b236d877788a4d54822e1401ce4d5175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5644 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2e17e1b2ad48dd94ee37e0642591ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cf5c139cf640d9b15f707ba79efbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process(batch):\n",
    "    inputs = tokenizer(batch[\"argument\"], truncation=True, padding=\"max_length\")\n",
    "    return {\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"],\n",
    "            \"labels\": batch[\"label\"],\n",
    "        }\n",
    "    \n",
    "tokenized_dataset = dataset.map(process, batched=True, remove_columns=['type', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            do_eval=True,\n",
    "            do_train=True,\n",
    "            num_train_epochs=6,\n",
    "            save_total_limit=2,\n",
    "            load_best_model_at_end=True,\n",
    "            learning_rate=1e-03,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            save_strategy=\"steps\",\n",
    "            logging_strategy=\"steps\",\n",
    "            evaluation_strategy=\"steps\",\n",
    "            logging_steps=60,\n",
    "            eval_steps=60,\n",
    "            save_steps=60,\n",
    "        )\n",
    "\n",
    "def compute_metrics(pred):\n",
    "            print(pred)\n",
    "            print(\"======================================\")\n",
    "            labels = pred.label_ids\n",
    "            preds = pred.predictions.argmax(-1)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                labels, preds, average=\"weighted\"\n",
    "            )\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            compute_metrics=compute_metrics,\n",
    "            train_dataset=tokenized_dataset[\"train\"],\n",
    "            eval_dataset=tokenized_dataset[\"validation\"],\n",
    "            tokenizer=tokenizer,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1825, 'learning_rate': 0.0009716713881019831, 'epoch': 0.17}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f53a34a1160>\n",
      "======================================\n",
      "{'eval_loss': 1.1063247919082642, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 14.0959, 'eval_samples_per_second': 51.434, 'eval_steps_per_second': 3.263, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1028, 'learning_rate': 0.000943342776203966, 'epoch': 0.34}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f533d6b97f0>\n",
      "======================================\n",
      "{'eval_loss': 1.1005462408065796, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 14.0942, 'eval_samples_per_second': 51.44, 'eval_steps_per_second': 3.264, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1006, 'learning_rate': 0.0009150141643059491, 'epoch': 0.51}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f533d6b2400>\n",
      "======================================\n",
      "{'eval_loss': 1.100216269493103, 'eval_accuracy': 0.3213793103448276, 'eval_f1': 0.15632855805917503, 'eval_precision': 0.103284661117717, 'eval_recall': 0.3213793103448276, 'eval_runtime': 13.9685, 'eval_samples_per_second': 51.903, 'eval_steps_per_second': 3.293, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1075, 'learning_rate': 0.000886685552407932, 'epoch': 0.68}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f55684c81f0>\n",
      "======================================\n",
      "{'eval_loss': 1.0997376441955566, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 13.9819, 'eval_samples_per_second': 51.853, 'eval_steps_per_second': 3.29, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1022, 'learning_rate': 0.0008583569405099151, 'epoch': 0.85}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f556a75cee0>\n",
      "======================================\n",
      "{'eval_loss': 1.0975046157836914, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 13.9665, 'eval_samples_per_second': 51.91, 'eval_steps_per_second': 3.294, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0962, 'learning_rate': 0.000830028328611898, 'epoch': 1.02}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f55685e17c0>\n",
      "======================================\n",
      "{'eval_loss': 1.1050671339035034, 'eval_accuracy': 0.3213793103448276, 'eval_f1': 0.15632855805917503, 'eval_precision': 0.103284661117717, 'eval_recall': 0.3213793103448276, 'eval_runtime': 13.9082, 'eval_samples_per_second': 52.128, 'eval_steps_per_second': 3.307, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1023, 'learning_rate': 0.0008016997167138811, 'epoch': 1.19}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f55686e1eb0>\n",
      "======================================\n",
      "{'eval_loss': 1.101406455039978, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 14.0869, 'eval_samples_per_second': 51.466, 'eval_steps_per_second': 3.265, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1022, 'learning_rate': 0.000773371104815864, 'epoch': 1.36}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f535c6db340>\n",
      "======================================\n",
      "{'eval_loss': 1.100594401359558, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 13.952, 'eval_samples_per_second': 51.964, 'eval_steps_per_second': 3.297, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1042, 'learning_rate': 0.0007450424929178471, 'epoch': 1.53}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f55686d00a0>\n",
      "======================================\n",
      "{'eval_loss': 1.0979384183883667, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 13.9772, 'eval_samples_per_second': 51.87, 'eval_steps_per_second': 3.291, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1002, 'learning_rate': 0.00071671388101983, 'epoch': 1.7}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f55686d00a0>\n",
      "======================================\n",
      "{'eval_loss': 1.0999361276626587, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 14.0919, 'eval_samples_per_second': 51.448, 'eval_steps_per_second': 3.264, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0845, 'learning_rate': 0.0006883852691218131, 'epoch': 1.87}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f535c5cbe80>\n",
      "======================================\n",
      "{'eval_loss': 1.1115469932556152, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 14.1217, 'eval_samples_per_second': 51.339, 'eval_steps_per_second': 3.257, 'epoch': 1.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1032, 'learning_rate': 0.000660056657223796, 'epoch': 2.04}\n",
      "<transformers.trainer_utils.EvalPrediction object at 0x7f535c6dbfa0>\n",
      "======================================\n",
      "{'eval_loss': 1.0975288152694702, 'eval_accuracy': 0.35724137931034483, 'eval_f1': 0.18805999439304738, 'eval_precision': 0.12762140309155767, 'eval_recall': 0.35724137931034483, 'eval_runtime': 14.0906, 'eval_samples_per_second': 51.453, 'eval_steps_per_second': 3.265, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/lucaM/LogicalFallacyRepo/logical-fallacy-LLMs/logicalfallacies/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "if not LOAD_SAVED_MODEL:\n",
    "    trainer.train()\n",
    "    trainer.save_model(\"models/binary/electra_classifier\")\n",
    "    predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
    "    print(predictions.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logicalfallacies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
